# Augmentation data generators

aug1 = transforms.Compose([
       transforms.ToPILImage(),
       transforms.ToTensor(),
       transforms.Normalize(mean=[0.485, 0.456, 0.406],
                            std=[0.229, 0.224, 0.225])
])


aug2 = transforms.Compose([
        transforms.ToPILImage(),
        transforms.RandomChoice([
            transforms.RandomRotation((0,0)),
            transforms.RandomHorizontalFlip(p=1),
            transforms.RandomVerticalFlip(p=1),
            transforms.RandomRotation((90,90)),
            transforms.RandomRotation((180,180)),
            transforms.RandomRotation((270,270)),
        ]),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
])


aug3 = transforms.Compose([
        transforms.ToPILImage(),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(100),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
])

# Augmentation dataset & data loaders
test_dataset1 = RetinaDataset(df=test_df, img_dir=test_img_dir, transforms=aug1)
test_dataset2 = RetinaDataset(df=test_df, img_dir=test_img_dir, transforms=aug2)
test_dataset3 = RetinaDataset(df=test_df, img_dir=test_img_dir, transforms=aug3)

tl1 = DataLoader(dataset=test_dataset1, batch_size=16, shuffle=False)
tl2 = DataLoader(dataset=test_dataset2, batch_size=16, shuffle=False)
tl3 = DataLoader(dataset=test_dataset3, batch_size=16, shuffle=False)





tta_loaders = [tl1, tl2, tl3]

t1,t2,t3 = [], [], []
preds = [t1, t2, t3]
for i in range(len(tta_loaders)):
    with torch.no_grad():
        model.eval()
        for data, target in tta_loaders[i]:
            data = data.to(device)
            target = target.to(device)
            outputs = model(data)
            for probs in outputs:
                #print(prob)
                preds[i].append(probs.detach().cpu().numpy())
                
end = [(a+b+c) / 3 for a,b,c in zip(t1, t2, t3)]

predictions = []
for prob in end:   
    idx = np.argmax(prob)
    #pred = rectification(prob[idx])
    predictions.append(idx)





import matplotlib.pyplot as plt
from torchvision.utils import make_grid

def show_augmented_images(dataset, num_images=5):
    # Get the first batch from the DataLoader
    loader = DataLoader(dataset, batch_size=num_images, shuffle=True)
    images, _ = next(iter(loader))
    
    # Denormalize the images if necessary
    mean = torch.tensor([0.485, 0.456, 0.406])
    std = torch.tensor([0.229, 0.224, 0.225])
    images = images * std[:, None, None] + mean[:, None, None]
    
    # Create a grid of images
    grid_img = make_grid(images, nrow=num_images)
    
    # Convert the grid to a numpy array and transpose to (H, W, C)
    np_grid_img = grid_img.permute(1, 2, 0).numpy()
    
    # Display the images
    plt.figure(figsize=(15, 5))
    plt.imshow(np_grid_img)
    plt.axis('off')
    plt.show()

# Display images from the first augmentation set
print("Augmentation Set 1")
show_augmented_images(test_dataset1)

# Display images from the second augmentation set
print("Augmentation Set 2")
show_augmented_images(test_dataset2)

# Display images from the third augmentation set
print("Augmentation Set 3")
show_augmented_images(test_dataset3)





import torch
import numpy as np
from torch.utils.data import DataLoader

# List of augmentation transforms
tta_transforms = [aug1, aug2, aug3]

# List to store predictions from each TTA iteration
tta_predictions = []

# Iterate over each TTA transform
for transform in tta_transforms:
    # Create a new DataLoader with the current TTA transform
    tta_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)
    
    # List to store predictions for the current TTA transform
    predictions = []
    
    # Evaluate the model on the test dataset with the current TTA transform
    with torch.no_grad():
        for images, _ in tta_loader:
            images = images.to(device)
            # Apply TTA transform to each image individually
            transformed_images = torch.stack([transform(img) for img in images]).to(device)
            outputs = model(transformed_images)
            predictions.extend(outputs.argmax(dim=1).cpu().numpy())
    
    # Append predictions for the current TTA transform to the list
    tta_predictions.append(predictions)

# Calculate the final predictions by averaging predictions from all TTA iterations
final_predictions = np.mean(tta_predictions, axis=0).astype(int)

# Display test accuracy and test loss
with torch.no_grad():
    model.eval()
    correct = 0
    total = 0
    test_loss = 0
    criterion = nn.CrossEntropyLoss()
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels)
        test_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    test_loss /= len(test_loader.dataset)
    accuracy = correct / total

print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}')



